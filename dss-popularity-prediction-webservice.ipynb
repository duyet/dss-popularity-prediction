{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import svm\n",
    "from sklearn import neighbors\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, KFold, GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score, auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./OnlineNewsPopularity/OnlineNewsPopularity.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(39644, 61)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>timedelta</th>\n",
       "      <th>n_tokens_title</th>\n",
       "      <th>n_tokens_content</th>\n",
       "      <th>n_unique_tokens</th>\n",
       "      <th>n_non_stop_words</th>\n",
       "      <th>n_non_stop_unique_tokens</th>\n",
       "      <th>num_hrefs</th>\n",
       "      <th>num_self_hrefs</th>\n",
       "      <th>num_imgs</th>\n",
       "      <th>...</th>\n",
       "      <th>min_positive_polarity</th>\n",
       "      <th>max_positive_polarity</th>\n",
       "      <th>avg_negative_polarity</th>\n",
       "      <th>min_negative_polarity</th>\n",
       "      <th>max_negative_polarity</th>\n",
       "      <th>title_subjectivity</th>\n",
       "      <th>title_sentiment_polarity</th>\n",
       "      <th>abs_title_subjectivity</th>\n",
       "      <th>abs_title_sentiment_polarity</th>\n",
       "      <th>shares</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>http://mashable.com/2013/01/07/amazon-instant-...</td>\n",
       "      <td>731.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>219.0</td>\n",
       "      <td>0.663594</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.815385</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.7</td>\n",
       "      <td>-0.350000</td>\n",
       "      <td>-0.600</td>\n",
       "      <td>-0.200000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>-0.187500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.187500</td>\n",
       "      <td>593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>http://mashable.com/2013/01/07/ap-samsung-spon...</td>\n",
       "      <td>731.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>0.604743</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.791946</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.7</td>\n",
       "      <td>-0.118750</td>\n",
       "      <td>-0.125</td>\n",
       "      <td>-0.100000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>http://mashable.com/2013/01/07/apple-40-billio...</td>\n",
       "      <td>731.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>211.0</td>\n",
       "      <td>0.575130</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.663866</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.466667</td>\n",
       "      <td>-0.800</td>\n",
       "      <td>-0.133333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>http://mashable.com/2013/01/07/astronaut-notre...</td>\n",
       "      <td>731.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>531.0</td>\n",
       "      <td>0.503788</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.665635</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>0.8</td>\n",
       "      <td>-0.369697</td>\n",
       "      <td>-0.600</td>\n",
       "      <td>-0.166667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>http://mashable.com/2013/01/07/att-u-verse-apps/</td>\n",
       "      <td>731.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1072.0</td>\n",
       "      <td>0.415646</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.540890</td>\n",
       "      <td>19.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.220192</td>\n",
       "      <td>-0.500</td>\n",
       "      <td>-0.050000</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>0.045455</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>505</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 url   timedelta  \\\n",
       "0  http://mashable.com/2013/01/07/amazon-instant-...       731.0   \n",
       "1  http://mashable.com/2013/01/07/ap-samsung-spon...       731.0   \n",
       "2  http://mashable.com/2013/01/07/apple-40-billio...       731.0   \n",
       "3  http://mashable.com/2013/01/07/astronaut-notre...       731.0   \n",
       "4   http://mashable.com/2013/01/07/att-u-verse-apps/       731.0   \n",
       "\n",
       "    n_tokens_title   n_tokens_content   n_unique_tokens   n_non_stop_words  \\\n",
       "0             12.0              219.0          0.663594                1.0   \n",
       "1              9.0              255.0          0.604743                1.0   \n",
       "2              9.0              211.0          0.575130                1.0   \n",
       "3              9.0              531.0          0.503788                1.0   \n",
       "4             13.0             1072.0          0.415646                1.0   \n",
       "\n",
       "    n_non_stop_unique_tokens   num_hrefs   num_self_hrefs   num_imgs   ...     \\\n",
       "0                   0.815385         4.0              2.0        1.0   ...      \n",
       "1                   0.791946         3.0              1.0        1.0   ...      \n",
       "2                   0.663866         3.0              1.0        1.0   ...      \n",
       "3                   0.665635         9.0              0.0        1.0   ...      \n",
       "4                   0.540890        19.0             19.0       20.0   ...      \n",
       "\n",
       "    min_positive_polarity   max_positive_polarity   avg_negative_polarity  \\\n",
       "0                0.100000                     0.7               -0.350000   \n",
       "1                0.033333                     0.7               -0.118750   \n",
       "2                0.100000                     1.0               -0.466667   \n",
       "3                0.136364                     0.8               -0.369697   \n",
       "4                0.033333                     1.0               -0.220192   \n",
       "\n",
       "    min_negative_polarity   max_negative_polarity   title_subjectivity  \\\n",
       "0                  -0.600               -0.200000             0.500000   \n",
       "1                  -0.125               -0.100000             0.000000   \n",
       "2                  -0.800               -0.133333             0.000000   \n",
       "3                  -0.600               -0.166667             0.000000   \n",
       "4                  -0.500               -0.050000             0.454545   \n",
       "\n",
       "    title_sentiment_polarity   abs_title_subjectivity  \\\n",
       "0                  -0.187500                 0.000000   \n",
       "1                   0.000000                 0.500000   \n",
       "2                   0.000000                 0.500000   \n",
       "3                   0.000000                 0.500000   \n",
       "4                   0.136364                 0.045455   \n",
       "\n",
       "    abs_title_sentiment_polarity   shares  \n",
       "0                       0.187500      593  \n",
       "1                       0.000000      711  \n",
       "2                       0.000000     1500  \n",
       "3                       0.000000     1200  \n",
       "4                       0.136364      505  \n",
       "\n",
       "[5 rows x 61 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = [col.strip() for col in df.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "med = df['shares'].median()\n",
    "df['label'] = df['shares'].apply(lambda share: 1 if share > med else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=['url', 'label', 'shares'])\n",
    "y = df['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = df.drop(columns=['url', 'label', 'shares'])\n",
    "X = df\n",
    "y = df['label']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "\n",
    "X_train.to_csv('./web_data/X_train.csv', header=True, index=True)\n",
    "X_test.to_csv('./web_data/X_test.csv', header=True, index=True)\n",
    "\n",
    "y_train.to_csv('./web_data/y_train.csv', header=True, index=True)\n",
    "y_test.to_csv('./web_data/y_test.csv', header=True, index=True)\n",
    "\n",
    "X_train = X_train.drop(columns=['url', 'label', 'shares'])\n",
    "y_train = y_train.drop(columns=['url', 'label', 'shares'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM\n",
    "parameters = {'C': [2**i for i in range(0, 7)],\n",
    "              'kernel':('rbf', ), }\n",
    "tmp_model = svm.SVC()\n",
    "svc = GridSearchCV(tmp_model, parameters, cv=3, verbose=10, n_jobs=2)\n",
    "svc.fit(X, y)\n",
    "svc_best_params_ = svc.best_params_\n",
    "svc_best_score_ = svc.best_score_\n",
    "print('SVM', svc_best_params_, svc_best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVC\n",
    "svc_best_params_ = {'C': 2**1, 'kernel': 'linear'}\n",
    "svc = svm.SVC(**svc_best_params_)\n",
    "svc.fit(X_train, y_train)\n",
    "\n",
    "y_pred = svc.predict(X_test)\n",
    "y_true = y_test\n",
    "print('SVC')\n",
    "print(confusion_matrix(y_true, y_pred))\n",
    "print(accuracy_score(y_true, y_pred))\n",
    "print(precision_score(y_true, y_pred))\n",
    "print(recall_score(y_true, y_pred))\n",
    "print(f1_score(y_true, y_pred))\n",
    "# print(auc(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make output file for webservice\n",
    "X_test.join(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 12 candidates, totalling 36 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   1 tasks      | elapsed:    4.1s\n",
      "[Parallel(n_jobs=2)]: Done   4 tasks      | elapsed:    8.8s\n",
      "[Parallel(n_jobs=2)]: Done   9 tasks      | elapsed:   29.6s\n",
      "[Parallel(n_jobs=2)]: Done  14 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=2)]: Done  21 tasks      | elapsed:  3.9min\n",
      "[Parallel(n_jobs=2)]: Done  28 tasks      | elapsed:  5.3min\n",
      "[Parallel(n_jobs=2)]: Done  36 out of  36 | elapsed: 10.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random forest {'criterion': 'entropy', 'n_estimators': 10} 0.5623297346382807\n"
     ]
    }
   ],
   "source": [
    "# Random Forest\n",
    "parameters = {'criterion': ('gini', 'entropy'),\n",
    "             'n_estimators': [10, 20, 50, 100, 200, 400]}\n",
    "tmp_model = RandomForestClassifier()\n",
    "rf_model = GridSearchCV(tmp_model, parameters, cv=3, verbose=10, n_jobs=2)\n",
    "rf_model.fit(X, y)\n",
    "rf_best_score_ = rf_model.best_score_\n",
    "rf_best_params_ = rf_model.best_params_\n",
    "print('Random forest', rf_best_params_, rf_best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random forest\n",
      "[[4750 1920]\n",
      " [3013 3400]]\n",
      "0.6229458075364978\n",
      "0.6390977443609023\n",
      "0.5301730859192265\n",
      "0.5795619193727095\n"
     ]
    }
   ],
   "source": [
    "# Random Forest\n",
    "rf_model = RandomForestClassifier(**rf_best_params_)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = rf_model.predict(X_test)\n",
    "y_true = y_test\n",
    "print('Random forest')\n",
    "print(confusion_matrix(y_true, y_pred))\n",
    "print(accuracy_score(y_true, y_pred))\n",
    "print(precision_score(y_true, y_pred))\n",
    "print(recall_score(y_true, y_pred))\n",
    "print(f1_score(y_true, y_pred))\n",
    "# print(auc(y_true, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ada Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 15 candidates, totalling 45 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   1 tasks      | elapsed:    2.3s\n",
      "[Parallel(n_jobs=2)]: Done   4 tasks      | elapsed:    3.6s\n",
      "[Parallel(n_jobs=2)]: Done   9 tasks      | elapsed:    7.5s\n",
      "[Parallel(n_jobs=2)]: Done  14 tasks      | elapsed:   11.7s\n",
      "[Parallel(n_jobs=2)]: Done  21 tasks      | elapsed:   19.8s\n",
      "[Parallel(n_jobs=2)]: Done  28 tasks      | elapsed:   28.5s\n",
      "[Parallel(n_jobs=2)]: Done  37 tasks      | elapsed:   42.6s\n",
      "[Parallel(n_jobs=2)]: Done  45 out of  45 | elapsed:   57.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ada Boost {'n_estimators': 10} 0.548683281202704\n"
     ]
    }
   ],
   "source": [
    "# Ada Boost\n",
    "parameters = {'n_estimators': [10, 20, 50, 100, 200, 400]}\n",
    "tmp_model = AdaBoostClassifier()\n",
    "ab_model = GridSearchCV(tmp_model, parameters, cv=3, verbose=10, n_jobs=2)\n",
    "ab_model.fit(X, y)\n",
    "ab_best_score_ = ab_model.best_score_\n",
    "ab_best_params_ = ab_model.best_params_\n",
    "print('Ada Boost', ab_best_params_, ab_best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoostClassifier\n",
      "[[4264 2406]\n",
      " [2237 4176]]\n",
      "0.6451119773752197\n",
      "0.6344576116681859\n",
      "0.6511772961172618\n",
      "0.642708734128511\n"
     ]
    }
   ],
   "source": [
    "# AdaBoostClassifier\n",
    "ab_best_params_ = {'n_estimators': 10}\n",
    "ab_model = AdaBoostClassifier(**ab_best_params_)\n",
    "ab_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = ab_model.predict(X_test)\n",
    "y_true = y_test\n",
    "print('AdaBoostClassifier')\n",
    "print(confusion_matrix(y_true, y_pred))\n",
    "print(accuracy_score(y_true, y_pred))\n",
    "print(precision_score(y_true, y_pred))\n",
    "print(recall_score(y_true, y_pred))\n",
    "print(f1_score(y_true, y_pred))\n",
    "# print(auc(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 39 candidates, totalling 117 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   1 tasks      | elapsed:   26.6s\n",
      "[Parallel(n_jobs=2)]: Done   4 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=2)]: Done   9 tasks      | elapsed:  2.7min\n",
      "[Parallel(n_jobs=2)]: Done  14 tasks      | elapsed:  4.6min\n",
      "[Parallel(n_jobs=2)]: Done  21 tasks      | elapsed:  7.1min\n",
      "[Parallel(n_jobs=2)]: Done  28 tasks      | elapsed: 10.3min\n",
      "[Parallel(n_jobs=2)]: Done  37 tasks      | elapsed: 14.9min\n",
      "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed: 19.1min\n",
      "[Parallel(n_jobs=2)]: Done  57 tasks      | elapsed: 24.4min\n",
      "[Parallel(n_jobs=2)]: Done  68 tasks      | elapsed: 29.2min\n",
      "[Parallel(n_jobs=2)]: Done  81 tasks      | elapsed: 34.5min\n",
      "[Parallel(n_jobs=2)]: Done  94 tasks      | elapsed: 41.2min\n",
      "[Parallel(n_jobs=2)]: Done 109 tasks      | elapsed: 48.5min\n",
      "[Parallel(n_jobs=2)]: Done 117 out of 117 | elapsed: 52.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN {'metric': 'euclidean', 'n_neighbors': 35} 0.5703763495106448\n"
     ]
    }
   ],
   "source": [
    "# KNN\n",
    "parameters = {'metric': ('euclidean', ),\n",
    "             'n_neighbors': [1, 3, 5, 10, 20]}\n",
    "tmp_model = neighbors.KNeighborsClassifier()\n",
    "knn_model = GridSearchCV(tmp_model, parameters, cv=3, verbose=10, n_jobs=2)\n",
    "knn_model.fit(X, y)\n",
    "knn_best_params_ = knn_model.best_params_\n",
    "knn_best_score_ = knn_model.best_score_\n",
    "print('KNN', knn_best_params_, knn_best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN\n",
      "[[4106 2564]\n",
      " [2893 3520]]\n",
      "0.5828938316899793\n",
      "0.5785667324128863\n",
      "0.548885077186964\n",
      "0.5633352004481075\n"
     ]
    }
   ],
   "source": [
    "# KNN\n",
    "knn_model = neighbors.KNeighborsClassifier(**knn_best_params_)\n",
    "knn_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = knn_model.predict(X_test)\n",
    "y_true = y_test\n",
    "print('KNN')\n",
    "print(confusion_matrix(y_true, y_pred))\n",
    "print(accuracy_score(y_true, y_pred))\n",
    "print(precision_score(y_true, y_pred))\n",
    "print(recall_score(y_true, y_pred))\n",
    "print(f1_score(y_true, y_pred))\n",
    "# print(auc(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes: No need to tune\n",
      "Naive Bayes\n",
      "[[6335  335]\n",
      " [5764  649]]\n",
      "0.5338225177711534\n",
      "0.6595528455284553\n",
      "0.10120068610634649\n",
      "0.17547654454508585\n"
     ]
    }
   ],
   "source": [
    "# Naive Bayes\n",
    "print('Naive Bayes: No need to tune',)\n",
    "nb_model = GaussianNB()\n",
    "nb_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = nb_model.predict(X_test)\n",
    "y_true = y_test\n",
    "print('Naive Bayes')\n",
    "print(confusion_matrix(y_true, y_pred))\n",
    "print(accuracy_score(y_true, y_pred))\n",
    "print(precision_score(y_true, y_pred))\n",
    "print(recall_score(y_true, y_pred))\n",
    "print(f1_score(y_true, y_pred))\n",
    "# print(auc(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
